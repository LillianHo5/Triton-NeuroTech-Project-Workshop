{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0edfeb57-2656-48df-ba61-f39ed677f0c7",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9adec60-8e26-4949-8464-93769349993a",
   "metadata": {},
   "source": [
    "## Download required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f5f94c-a4cb-40a4-88bd-d583f62cbcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael\\.virtualenvs\\Triton-NeuroTech-Project-Workshop\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "from numpy.fft import rfft, irfft, rfftfreq\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from matplotlib import patches\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "import pandas as pd\n",
    "\n",
    "import mne\n",
    "\n",
    "from scipy.fftpack import fft\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from scipy.signal import sosfiltfilt\n",
    "from sklearn.pipeline import clone\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from meegkit import dss, ress\n",
    "from meegkit import sns as msns\n",
    "from meegkit.utils import unfold, rms, fold, tscov, matmul3d\n",
    "\n",
    "from brainda.paradigms import SSVEP\n",
    "from brainda.algorithms.utils.model_selection import (\n",
    "    set_random_seeds, \n",
    "    generate_loo_indices, match_loo_indices)\n",
    "from brainda.algorithms.decomposition import (\n",
    "    FBTRCA, FBTDCA, FBSCCA, FBECCA, FBDSP,\n",
    "    generate_filterbank, generate_cca_references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52119ea-d007-4df6-a071-e1ba0ea7dd82",
   "metadata": {},
   "source": [
    "## Experimental constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "082524f1-ac41-4362-b4a7-564c87dc82cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dirs = ['run1/','run2/','run3/','run4/','run5/','run6/','run7/','run8/','run9/']  # each folder is a single independent run\n",
    "duration = 1.5  # duration of a trial in seconds\n",
    "n_trials = 2  \n",
    "n_classes = 32  # number of classes, 8 freq, 4 phase, total of 8 * 4 = 32 targets\n",
    "n_channels = 19  # number of recording channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33610649-1789-496c-a346-7b4001cd8c2e",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1792679f-b1bd-473f-8048-5639b193c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_temp_function(eeg, meta, classes, stim_duration=5, filter=True):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    trials = meta[1:,:2]\n",
    "    times = []\n",
    "    duration_samples = int(stim_duration*300)\n",
    "    for index, row in eeg.loc[eeg[' TRG']==16.0].iterrows():\n",
    "        if index > 0 and eeg.iloc[index-1][' TRG'] == 0 and (not eeg.iloc[index:index+duration_samples][' TRG'].isin([18.0]).any()):\n",
    "            times.append(row['time'])\n",
    "    times = np.array(times)\n",
    "    \n",
    "    eeg = np.array([eeg.loc[eeg['time']>t].drop(columns=['time',' TRG',' X1',' X2',' X3',' A2']).to_numpy()[:duration_samples].T for t in times])\n",
    "    if filter:\n",
    "        eeg = mne.filter.filter_data(eeg, sfreq=300, l_freq=5, h_freq=49, verbose=0, method='fir')\n",
    "    eeg_temp = []\n",
    "    for i in range(len(classes)):\n",
    "        eeg_temp.append([])\n",
    "    for i,freq in enumerate(trials):\n",
    "        for j,target in enumerate(classes):\n",
    "            if (freq==target).all():\n",
    "                eeg_temp[j].append(eeg[i])\n",
    "    eeg = np.array(eeg_temp).transpose(1,0,2,3)\n",
    "    return eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b2a64fc-9a43-489d-b859-141c056247c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((18, 32, 19, 450), (18, 32, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load experimental dataset\n",
    "eeg_whole = np.zeros((n_trials*len(sub_dirs),n_classes,n_channels,int(duration*300)))\n",
    "target_tab = {}\n",
    "# i_class = 0\n",
    "for i_dir,sub_dir in enumerate(sub_dirs):\n",
    "    print(i_dir)\n",
    "    data_path = \"../data/\" + sub_dir\n",
    "    eeg = pd.read_csv(data_path + 'eeg.csv').astype(float)\n",
    "    meta = np.loadtxt(data_path + 'meta.csv', delimiter=',', dtype=float)\n",
    "    trials = meta[1:,:2]\n",
    "    classes = np.unique(trials, axis=0)\n",
    "    more_targets = {tuple(target):index for index,target in enumerate(classes)}\n",
    "    target_tab.update(more_targets)\n",
    "    eeg = load_data_temp_function(eeg, meta, classes, stim_duration=duration,filter=False)\n",
    "    eeg_whole[i_dir*n_trials:(i_dir+1)*n_trials,:,:,:] = eeg\n",
    "    # i_class+=3\n",
    "eeg = eeg_whole\n",
    "target_by_trial = [list(target_tab.keys())] * n_trials*len(sub_dirs)\n",
    "eeg.shape, np.array(target_by_trial).shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dacde19-0d46-415d-9bfe-f3408873146f",
   "metadata": {},
   "source": [
    "## Will be fixed 8/9/2022 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d35fa04-42ba-4cc6-8ff3-6c87c7343172",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FBTDCA' object has no attribute 'l'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 48>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m trainX, trainY \u001b[38;5;241m=\u001b[39m filterX[train_ind], filterY[train_ind]\n\u001b[0;32m     64\u001b[0m testX, testY \u001b[38;5;241m=\u001b[39m filterX[test_ind], filterY[test_ind]\n\u001b[1;32m---> 66\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     67\u001b[0m     trainX, trainY,\n\u001b[0;32m     68\u001b[0m     Yf\u001b[38;5;241m=\u001b[39mYf\n\u001b[0;32m     69\u001b[0m )\n\u001b[0;32m     70\u001b[0m pred_labels \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(testX)\n\u001b[0;32m     71\u001b[0m loo_accs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     72\u001b[0m     balanced_accuracy_score(testY, pred_labels))\n",
      "File \u001b[1;32m~\\.virtualenvs\\Triton-NeuroTech-Project-Workshop\\lib\\site-packages\\sklearn\\base.py:85\u001b[0m, in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m     78\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot clone object \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit does not seem to be a scikit-learn \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator as it does not implement a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     81\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mrepr\u001b[39m(estimator), \u001b[38;5;28mtype\u001b[39m(estimator))\n\u001b[0;32m     82\u001b[0m             )\n\u001b[0;32m     84\u001b[0m klass \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\n\u001b[1;32m---> 85\u001b[0m new_object_params \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m new_object_params\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     87\u001b[0m     new_object_params[name] \u001b[38;5;241m=\u001b[39m clone(param, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\.virtualenvs\\Triton-NeuroTech-Project-Workshop\\lib\\site-packages\\sklearn\\base.py:211\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    209\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names():\n\u001b[1;32m--> 211\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m    213\u001b[0m         deep_items \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mget_params()\u001b[38;5;241m.\u001b[39mitems()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FBTDCA' object has no attribute 'l'"
     ]
    }
   ],
   "source": [
    "n_trials = eeg.shape[0]\n",
    "classes = range(n_classes)\n",
    "n_classes = len(classes)\n",
    "y = np.array([list(target_tab.values())] * n_trials).T.reshape(-1)\n",
    "eeg_temp = eeg[:n_trials,classes,:,40:]\n",
    "X = eeg_temp.swapaxes(0,1).reshape(-1,*eeg_temp.shape[2:])\n",
    "\n",
    "\n",
    "freq_targets = np.array(target_by_trial)[0,:,0]\n",
    "phase_targets = np.array(target_by_trial)[0,:,1]\n",
    "n_harmonics = 5\n",
    "n_bands = 3\n",
    "srate = 300  # sampling rate\n",
    "duration = 1  # duration to use for modeling\n",
    "Yf = generate_cca_references(\n",
    "    freq_targets, srate, duration, \n",
    "    phases=phase_targets, \n",
    "    n_harmonics=n_harmonics)\n",
    "wp = [[8*i, 90] for i in range(1, n_bands+1)]\n",
    "ws = [[8*i-2, 95] for i in range(1, n_bands+1)]\n",
    "filterbank = generate_filterbank(\n",
    "    wp, ws, srate, order=4, rp=1)\n",
    "filterweights = np.arange(1, len(filterbank)+1)**(-1.25) + 0.25\n",
    "set_random_seeds(64)\n",
    "l = 5\n",
    "models = OrderedDict([\n",
    "    # ('fbscca', FBSCCA(\n",
    "    #         filterbank, filterweights=filterweights)),\n",
    "    # ('fbecca', FBECCA(\n",
    "    #         filterbank, filterweights=filterweights)),\n",
    "    ('fbdsp', FBDSP(\n",
    "            filterbank, filterweights=filterweights)),\n",
    "    ('fbtrca', FBTRCA(\n",
    "            filterbank, filterweights=filterweights)),\n",
    "    ('fbtdca', FBTDCA(\n",
    "            filterbank, l, n_components=8, \n",
    "            filterweights=filterweights)),\n",
    "])\n",
    "events = []\n",
    "for j_class in classes:\n",
    "    events.extend([str(target_by_trial[i_trial][j_class]) for i_trial in range(n_trials)])\n",
    "events = np.array(events)\n",
    "subjects = ['1'] * (n_classes*n_trials)\n",
    "meta = pd.DataFrame(data=np.array([subjects,events]).T, columns=[\"subject\", \"event\"])\n",
    "set_random_seeds(42)\n",
    "loo_indices = generate_loo_indices(meta)\n",
    "\n",
    "for model_name in models:\n",
    "    if model_name == 'fbtdca':\n",
    "        filterX, filterY = np.copy(X[..., :int(srate*duration)+l]), np.copy(y)\n",
    "    else:\n",
    "        filterX, filterY = np.copy(X[..., :int(srate*duration)]), np.copy(y)\n",
    "    \n",
    "    filterX = filterX - np.mean(filterX, axis=-1, keepdims=True)\n",
    "\n",
    "    n_loo = len(loo_indices['1'][events[0]])\n",
    "    loo_accs = []\n",
    "    for k in range(n_loo):\n",
    "        train_ind, validate_ind, test_ind = match_loo_indices(\n",
    "            k, meta, loo_indices)\n",
    "        train_ind = np.concatenate([train_ind, validate_ind])\n",
    "\n",
    "        trainX, trainY = filterX[train_ind], filterY[train_ind]\n",
    "        testX, testY = filterX[test_ind], filterY[test_ind]\n",
    "\n",
    "        model = clone(models[model_name]).fit(\n",
    "            trainX, trainY,\n",
    "            Yf=Yf\n",
    "        )\n",
    "        pred_labels = model.predict(testX)\n",
    "        loo_accs.append(\n",
    "            balanced_accuracy_score(testY, pred_labels))\n",
    "    print(\"Model:{} LOO Acc:{:.2f}\".format(model_name, np.mean(loo_accs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
